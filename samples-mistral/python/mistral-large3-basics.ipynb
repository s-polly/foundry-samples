{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214bf61f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57191231",
   "metadata": {},
   "source": [
    "Mistral Large 3 is Mistralâ€™s first mixture-of-experts model since the seminal Mixtral series, and represents a substantial step forward in pretraining at Mistral. After post-training, the model achieves parity with the best instruction-tuned open-weight models on the market on general prompts, while also demonstrating image understanding and best-in-class performance on multilingual conversations (i.e., non-English/Chinese).\n",
    "\n",
    "Mistral Large 3 debuts at #2 in the OSS non-reasoning models category (#6 amongst OSS models overall) on the <a href=\"https://lmarena.ai/leaderboard/text\">LMArena leaderboard</a> and is released under the Apache 2.0 license."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc66f7",
   "metadata": {},
   "source": [
    "In this notebook, we will show how some basics on how to work with Mistral Large 3 in Microsoft Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf20ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fea685",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_AI_FOUNDRY_PROJECT_ENDPOINT = \"\"\n",
    "AZURE_AI_FOUNDRY_KEY = \"\"\n",
    "AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791bf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {AZURE_AI_FOUNDRY_KEY}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdaa694",
   "metadata": {},
   "source": [
    "## Compound questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966f03e",
   "metadata": {},
   "source": [
    "In chat and search use cases users can often ask questions that are complex, abstract, or are actually multiple questions within a single query. Mistral Large 3 is able to handle these types of questions and provide comprehensive answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundQuestion1 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you explain the nature of the universe and make an analogy to butterflies?\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundQuestion1Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=compoundQuestion1,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(compoundQuestion1Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef421e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundQuestion2 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in Financial Services. Respond in professional and concise language.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"I recently started a hedge fund in the United States and want to take a client out for dinner, how much can I spend? \n",
    "                        Also I am interested in measuring risk in my trades, is there a formula or methodology that can help here?\"\"\",\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e65016",
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundQuestion2Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=compoundQuestion2,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(compoundQuestion2Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704cdad",
   "metadata": {},
   "source": [
    "## Long Document Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3273d1",
   "metadata": {},
   "source": [
    "Mistral Large 3 supports a 256k context window. This is useful working with long documents, code bases, or other long-format corporpora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c384d8",
   "metadata": {},
   "source": [
    "Source: https://www.gutenberg.org/ebooks/1184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://www.gutenberg.org/cache/epub/1184/pg1184.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pg1184.txt\", \"r\") as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ad09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first three volumes of the book\n",
    "matches = re.finditer(r\"VOLUME TWO\", file_content, re.IGNORECASE)\n",
    "if matches:\n",
    "    second_occurrence = next((m for i, m in enumerate(matches) if i == 1), None)\n",
    "    if second_occurrence:\n",
    "        extracted_text = file_content[: second_occurrence.start()].strip()\n",
    "    else:\n",
    "        extracted_text = file_content.strip()\n",
    "else:\n",
    "    extracted_text = file_content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "longDocument1 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"an you summarize the following text into a paragraph? Based on this text, is revenge the same thing as justice?  \n",
    "                        List the main characters and key themes. \n",
    "                        Can you explore and expand on how this work can be applied to moderm business and contemporary society? \n",
    "                        Content: {extracted_text}\"\"\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "longDocument1Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=longDocument1,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(longDocument1Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526f3e0",
   "metadata": {},
   "source": [
    "Source: https://www.gutenberg.org/ebooks/1497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://www.gutenberg.org/cache/epub/1497/pg1497.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c356f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pg1497.txt\", \"r\") as file:\n",
    "    plato = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de226e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first three volumes of the book\n",
    "matches = re.finditer(r\"BOOK I.\", plato, re.IGNORECASE)\n",
    "if matches:\n",
    "    third_occurrence = next((m for i, m in enumerate(matches) if i == 2), None)\n",
    "    if third_occurrence:\n",
    "        extracted_text_plato = plato[: third_occurrence.start()].strip()\n",
    "    else:\n",
    "        extracted_text_plato = plato.strip()\n",
    "else:\n",
    "    extracted_text_plato = plato.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "longDocument2 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Can you summarize the following text into a paragraph? Based on this text, what is the allegory of the cave?  \n",
    "                        What are some key philosophical teachings in this text? \n",
    "                        What teachings in this text can be seen with the first Matrix movie? \n",
    "                        Content: {extracted_text_plato}\"\"\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "longDocument2Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=longDocument2,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(longDocument2Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051096df",
   "metadata": {},
   "source": [
    "## Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5469cc",
   "metadata": {},
   "source": [
    "Math can be challenging for large language models. Mistral Large 3 is able to to handle a variety of math problems, including those that require complex reasoning and problem solving. This is useful for applications like tutoring, education, and research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "math1 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"The World Cup takes place in 2026 but has a limited number of tickets available through a ficticious ticket broker.\n",
    "                        They are only selling tickets to the Final to customers who have bought at least two tickets to the group stage, one from each round.\n",
    "                        I have $1000 to spend on tickets altogether, how can I optimize my spending to minimize the amount I have to spend on tickets I have to buy and still qualify to attend the final?\n",
    "                        Finals ticket cost: $500\"\n",
    "                        Qualifying Round 1:\n",
    "                        Game A: $350\n",
    "                        Game B: $400\n",
    "                        Game C: $300\n",
    "                        Qualifying Round 2\n",
    "                        Game D: $175\n",
    "                        Game E: $250\n",
    "                        Game F: $300\n",
    "                        \n",
    "                        Show your work and thought process\"\"\",\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "math1Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=math1,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(math1Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "math2 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"How many ways can you arrange the letters in the word 'camembert'? Also what other cheeses have similar letter arrangements?\"\"\",\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "math2Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=math2,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(math2Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc99932",
   "metadata": {},
   "source": [
    "## Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf2adf",
   "metadata": {},
   "source": [
    "Financial Services requires both domain knowledge as well as the ability to reason through complex problems. Mistral Large 3 is well-suited to handle ae these types of questions, and with its 256k context window, it can help support a variety of users and AI applications in this industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a07ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance1 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"What's the difference between EBITDA and EBIT? Can you give me an example?\"\"\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bc115",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance1Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=finance1,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca66b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(finance1Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance2 = {\n",
    "    \"model\": f\"{AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in Financial Services. Respond in professional and concise language.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"To calculate Earnings + Depreciations I need the WACC. But in order to calculate the WACC I need Earnings and Depreciation. What am I supposed to do?\"\"\",\n",
    "        },\n",
    "    ],\n",
    "    \"temperature\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43959107",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance2Response = requests.post(\n",
    "    url=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    json=finance2,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(finance2Response.json()[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cdb78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
